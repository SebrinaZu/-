sqrt((8-7.729236)/sqrt(7.729236))
(8-7.729236)/log(sqrt(7.729236))
(8-log(7.729236)/log(sqrt(7.729236))
(8-log(7.729236)/log(sqrt(7.729236))
(8-log(7.729236))/log(sqrt(7.729236))
log(sqrt(7.729236))
(8-log(7.729236,base=exp(1))/sqrt(7.729236)
rp1 <- residuals(f1, "pearson")
rp1 <- residuals(f1, "pearson")
rp1
f1$fitted.values
Y <- rpois(n, 10)
Y
n <- 1000
X <- rnorm(n, 1, 1)
b0 <- 2
b1 <- -0.1
mu <- exp(b0 + b1 * X)
Y <- rpois(n, mu)
f0 <- glm(Y ~ 1, family = poisson)
f1 <- glm(Y ~ X, family = poisson)
f1$fitted.values
plot(f1)
summary(f1$fitted.values)
count(f1$fitted.values)
frequency(f1$fitted.values)
freeny.y(f1$fitted.values)
freen(f1$fitted.values)
summary(Y)
freeny(Y)
table(Y)
set.seed(728)
n <- 1000
X <- rnorm(n, 1, 1)
b0 <- 2
b1 <- -0.1
mu <- exp(b0 + b1 * X)
Y <- rpois(n, mu)
f1 <- glm(Y ~ X, family = poisson)
unique_Y <- unique(Y)
fitted_values <- sapply(unique_Y, function(y) {
predict(f1, newdata = data.frame(X = mean(X)), type = "response")
})
# Print fitted values for each Y
for (i in seq_along(unique_Y)) {
cat("Y =", unique_Y[i], ": ", fitted_values[i], "\n")
}
fitted_values <- fitted(f1)
# Combine observed Y and fitted values into a data frame
fitted_data <- data.frame(Y = Y, Fitted = fitted_values)
fitted_data
fitted_data[Y=7]
fitted_data[fitted_data$Y == 7, ]
pearson_residuals <- residuals(f1, type = "pearson")
# Combine observed Y, fitted values, and Pearson residuals into a data frame
residual_data <- data.frame(Y = Y, Fitted = fitted_values, Pearson_Residuals = pearson_residuals)
# Filter residual_data for Y = 7
subset_residual_data <- residual_data[residual_data$Y == 7, ]
# Plot Pearson residuals against fitted values for Y = 7
plot(subset_residual_data$Fitted, subset_residual_data$Pearson_Residuals,
xlab = "Fitted Values", ylab = "Pearson Residuals",
main = "Pearson Residuals Plot (Y = 7)")
abline(h = 0, col = "red", lty = 2)  # Add horizontal line at y = 0
abline(lm(subset_residual_data$Pearson_Residuals ~ subset_residual_data$Fitted), col = "red")
# Generate random exponential data with mean shifted to 0
set.seed(123) # for reproducibility
lambda <- 0.5 # rate parameter for exponential distribution
n <- 1000 # sample size
exp_data <- rexp(n, rate = lambda) - 1/lambda # shift mean to 0
# Generate Q-Q plot
qqnorm(exp_data) # Q-Q plot
qqline(exp_data) # Add a reference line
library(reticulate)
# 安装Miniconda并创建环境
install_miniconda()
conda_create("r-tensorflow", packages = c("python=3.8", "tensorflow"))
# 确保使用正确的Python环境
use_condaenv("r-tensorflow", required = TRUE)
# 打印Python配置，确保使用的是正确的环境
py_config()
# 安装kerastuner
kerastuneR::install_kerastuner(python_path = '/Users/zheng73/Library/r-miniconda-arm64/envs/r-tensorflow/bin/python')
library(keras)
library(kerastuneR)
library(dplyr)
library(ggplot2)
library(caret)
library(lattice)
library(caret)
library(readr)
library(lubridate)
library(forecast)
library(Metrics)
library(abind)
library(data.table)
library(hms)
library(dplyr)
library(tidyr)
library(skimr)
library(extrafont)
library(stringr)
library(NbClust)
library(zoo)
# Define the function to build the BiLSTM model with hyperparameter tuning
build_model_BiLSTM <- function(hp) {
# Hyperparameters to tune
units1 <- hp$Int('units1', min_value = 100, max_value = 200, step = 25)
dropout_rate1 <- hp$Float('dropout1', min_value = 0.1, max_value = 0.5, step = 0.1)
model <- keras_model_sequential() %>%
bidirectional(layer_lstm(units = units1, activation = "relu", return_sequences = TRUE, dropout = dropout_rate1), input_shape = c(n_input, 2)) %>%
bidirectional(layer_lstm(units = 100, activation = "relu", return_sequences = TRUE, dropout = 0.2)) %>%
time_distributed(layer_dense(units = 100, activation = "relu")) %>%
time_distributed(layer_dense(units = 1, activation = "linear"))
# Compile model
model %>% compile(
loss = 'mse',
optimizer = optimizer_adam(learning_rate = 0.01)
)
return(model)
}
# Create a tuner object using Hyperband
tuner <- Hyperband(
build_model_BiLSTM,
objective = "val_loss",
max_epochs = 100,
factor = 3,
directory = "my_dir",
project_name = "BiLSTM_tuning"
)
# Create a tuner object using Hyperband
tuner <- Hyperband(
build_model_BiLSTM,
objective = "val_loss",
max_epochs = 100,
factor = 3,
directory = "my_dir",
project_name = "BiLSTM_tuning"
)
# Create a tuner object using Hyperband
tuner <- Hyperband(
build_model_BiLSTM,
objective = "val_loss",
max_epochs = 100,
factor = 3,
directory = "my_dir",
project_name = "BiLSTM_tuning"
)
reticulate::use_python()
reticulate::use_python("")
py_module_available()
py_install()
miniconda_uninstall()
py_available()
# Define the function to build the BiLSTM model with hyperparameter tuning
build_model_BiLSTM <- function(hp) {
# Hyperparameters to tune
units1 <- hp$Int('units1', min_value = 100, max_value = 200, step = 25)
dropout_rate1 <- hp$Float('dropout1', min_value = 0.1, max_value = 0.5, step = 0.1)
model <- keras_model_sequential() %>%
bidirectional(layer_lstm(units = units1, activation = "relu", return_sequences = TRUE, dropout = dropout_rate1), input_shape = c(n_input, 2)) %>%
bidirectional(layer_lstm(units = 100, activation = "relu", return_sequences = TRUE, dropout = 0.2)) %>%
time_distributed(layer_dense(units = 100, activation = "relu")) %>%
time_distributed(layer_dense(units = 1, activation = "linear"))
# Compile model
model %>% compile(
loss = 'mse',
optimizer = optimizer_adam(learning_rate = 0.01)
)
return(model)
}
# Create a tuner object using Hyperband
tuner <- Hyperband(
build_model_BiLSTM,
objective = "val_loss",
max_epochs = 100,
factor = 3,
directory = "my_dir",
project_name = "BiLSTM_tuning"
)
library(reticulate)
# 安装Miniconda并创建环境
install_miniconda()
conda_create("r-tensorflow", packages = c("python=3.8", "tensorflow"))
# 确保使用正确的Python环境
use_condaenv("r-tensorflow", required = TRUE)
# 确保使用正确的Python环境
use_condaenv("/Users/zheng73/Library/r-miniconda-arm64/envs/r-tensorflow/bin/python", required = TRUE)
# Create a tuner object using Hyperband
tuner <- Hyperband(
build_model_BiLSTM,
objective = "val_loss",
max_epochs = 100,
factor = 3,
directory = "my_dir",
project_name = "BiLSTM_tuning"
)
py_module_available()
py_module_available("keras_tuner")
conda_remove("r-tensorflow", packages = c("python=3.8", "tensorflow"))
miniconda_path()
py_module_available("keras_tuner")
library(reticulate)
miniconda_uninstall("/Users/zheng73/.virtualenvs/r-reticulate/bin/python")
miniconda_uninstall("Users/zheng73/Library/r-miniconda-arm64/envs/r-tensorflow/bin/python")
miniconda_path()
miniconda_uninstall(""/Users/zheng73/Library/r-miniconda-arm64"")
miniconda_uninstall("/Users/zheng73/Library/r-miniconda-arm64")
miniconda_path()
miniconda_uninstall("/Users/zheng73/Library/r-miniconda-arm64")
py_available()
# 打印Python配置，确保使用的是正确的环境
py_config()
miniconda_path()
miniconda_path()
use_python(NULL)
# 打印Python配置，确保使用的是正确的环境
py_config()
py_module_available("keras_tuner")
# 确保使用正确的Python环境
use_condaenv("/Users/zheng73/.virtualenvs/r-tensorflow/bin/python", required = TRUE)
# 安装Miniconda并创建环境
install_miniconda("/Users/zheng73/.virtualenvs/r-tensorflow/bin/python")
# 打印Python配置，确保使用的是正确的环境
py_config()
py_module_available("keras_tuner")
library(kerastuneR)
py_module_available("keras_tuner")
use_condaenv("r-tensorflow", required = TRUE)
library(reticulate)
miniconda_uninstall()
install_miniconda()
conda_create("r-tensorflow", packages = c("python=3.8", "tensorflow", "keras-tuner"))
use_condaenv("r-tensorflow", required = TRUE)
virtualenv_remove(envname = "r-tensorflow")
use_condaenv("r-tensorflow", required = TRUE)
use_condaenv("r-tensorflow", required = TRUE)
virtualenv_remove(envname = "r-tensorflow")
use_condaenv("r-tensorflow", required = TRUE)
# 删除现有的虚拟环境
reticulate::virtualenv_remove(envname = "r-tensorflow")
reticulate::conda_remove("r-tensorflow")
# 删除现有的虚拟环境
reticulate::virtualenv_remove(envname = "r-tensorflow")
Y
reticulate::conda_remove("r-tensorflow")
# 安装 Miniconda
reticulate::install_miniconda()
# 删除现有的虚拟环境
reticulate::virtualenv_remove(envname = "r-tensorflow")
# 删除现有的虚拟环境
reticulate::virtualenv_remove(envname = "r-miniconda")
# 删除现有的虚拟环境
reticulate::virtualenv_remove(envname = "r-miniconda")
reticulate::conda_remove("r-miniconda")
install_miniconda()
reticulate::conda_remove("r-miniconda-arm64")
yes
install_miniconda(force = TRUE)
conda_create("r-tensorflow", packages = c("python=3.8", "tensorflow", "keras-tuner"))
use_condaenv("r-tensorflow", required = TRUE)
library(reticulate)
miniconda_uninstall()
# 删除现有的虚拟环境
reticulate::virtualenv_remove(envname = "r-miniconda")
# 删除现有的虚拟环境
reticulate::virtualenv_remove(envname = "r-miniconda")
# 删除现有的虚拟环境
reticulate::virtualenv_remove(envname = "r-tensorflow")
virtualenv_remove(envname = "r-tensorflow")
install_miniconda(force = TRUE)
conda_create("r-tensorflow", packages = c("python=3.8", "tensorflow", "keras-tuner"))
use_condaenv("r-tensorflow", required = TRUE)
miniconda_path()
# 打印Python配置，确保使用的是正确的环境
py_config()
library(kerastuneR)
py_available()
py_module_available(kerastuner)
install_kerastuner("/Users/zheng73/Library/r-miniconda-arm64")
# 安装kerastuner
kerastuneR::install_kerastuner(python_path = '/Users/zheng73/Library/r-miniconda-arm64/envs/r-tensorflow/bin/python')
# 打印Python配置，确保使用的是正确的环境
py_config()
install.packages("kerastuneR")
py_module_available(kerastuner)
library(reticulate)
library(kerastuneR)
py_module_available(kerastuner)
library(keras)
library(kerastuneR)
library(dplyr)
library(ggplot2)
library(lattice)
library(caret)
library(readr)
library(lubridate)
library(forecast)
library(Metrics)
library(abind)
library(data.table)
library(hms)
library(dplyr)
library(tidyr)
library(skimr)
library(extrafont)
library(stringr)
library(NbClust)
library(zoo)
library(keras)
library(kerastuneR)
library(dplyr)
library(ggplot2)
library(lattice)
library(caret)
library(readr)
library(lubridate)
library(forecast)
library(Metrics)
library(abind)
library(data.table)
library(hms)
library(dplyr)
library(tidyr)
library(skimr)
library(extrafont)
library(stringr)
library(NbClust)
library(zoo)
n_input <- 48
input_shape <- c(n_input, 4)
input_layer <- layer_input(shape = input_shape, name = "Input layer")
time_steps <- input_shape[1]  # 时间步数
units_1 <- 100
units_2 <- 100
dropout_rate <- 0.2
lstm_out <- input_layer %>%
bidirectional(layer_lstm(units = units_1, activation = "relu", return_sequences = TRUE, dropout = dropout_rate, name = "BiLSTM layer 1")) %>%
bidirectional(layer_lstm(units = units_2, activation = "relu", return_sequences = TRUE, dropout = dropout_rate, name = "BiLSTM layer 2"))
attention_out <- list(lstm_out, attention) %>%
layer_multiply()
input_layer <- layer_input(shape = input_shape, name = "Input layer")
time_steps <- input_shape[1]  # 时间步数
units_1 <- 100
units_2 <- 100
dropout_rate <- 0.2
lstm_out <- input_layer %>%
bidirectional(layer_lstm(units = units_1, activation = "relu", return_sequences = TRUE, dropout = dropout_rate, name = "BiLSTM layer 1")) %>%
bidirectional(layer_lstm(units = units_2, activation = "relu", return_sequences = TRUE, dropout = dropout_rate, name = "BiLSTM layer 2"))
lstm_out <- input_layer %>%
bidirectional(layer_lstm(units = units_1, activation = "relu", return_sequences = TRUE, dropout = dropout_rate)) %>%
bidirectional(layer_lstm(units = units_2, activation = "relu", return_sequences = TRUE, dropout = dropout_rate))
attention <- lstm_out %>%
time_distributed(layer_dense(units = 1, activation = 'softmax')) %>%
layer_lambda(function(x) k_sum(x, axis = -1))
attention <- attention %>%
layer_lambda(function(x) k_expand_dims(x, axis = -1))
attention_out <- list(lstm_out, attention) %>%
layer_multiply()
output_layer <- attention_out %>%
time_distributed(layer_dense(units = 50, activation = "relu")) %>%
time_distributed(layer_dense(units = 1, activation = "linear"))
model <- keras_model(inputs = input_layer, outputs = output_layer)
summary(model)
setwd("/Users/zheng73/Desktop/实习/深圳/EV/Load forecasting/MF EV charging analysis")
library(ggplot2)
library(lattice)
library(caret)
library(readr)
library(lubridate)
library(forecast)
library(Metrics)
library(abind)
library(data.table)
library(hms)
library(dplyr)
library(tidyr)
library(skimr)
library(extrafont)
library(stringr)
library(NbClust)
library(zoo)
library(ggplot2)
library(lattice)
library(caret)
library(readr)
library(lubridate)
library(forecast)
library(Metrics)
library(abind)
library(data.table)
library(hms)
library(dplyr)
library(tidyr)
library(skimr)
library(extrafont)
library(stringr)
library(NbClust)
library(zoo)
ChargingRecords <- data.table::fread("ChargingRecords.csv")
ChargingRecords[,StartDatetime := lubridate::ymd_hms(paste(StartDay, StartTime, sep = " "))]
ChargingRecords[,EndDatetime := lubridate::ymd_hms(paste(EndDay, EndTime, sep = " "))]
ChargingRecords[,StartTime := as_hms(StartTime)]
ChargingRecords[,EndTime := as_hms(EndTime)]
ChargingRecords[,StartDay := as_date(StartDay)]
ChargingRecords[,EndDay := as_date(EndDay)]
ChargingRecords[,StartDatehour := lubridate::ymd_hm(paste(StartDay, sprintf("%02d:00", hour(StartTime)), sep = " "))]
ChargingRecords[,EndDatehour := lubridate::ymd_hm(paste(EndDay, sprintf("%02d:00", hour(EndTime)), sep = " "))]
ChargingRecords[,Startmin:=as.numeric(round(StartTime/60))]
ChargingRecords[which(ChargingRecords$Startmin==0), which(names(ChargingRecords)=="Startmin")]<-1440
ChargingRecords[,Endmin:=as.numeric(round(EndTime/60))]
ChargingRecords[which(ChargingRecords$Endmin==0), which(names(ChargingRecords)=="Endmin")]<-1440
start_time <- as_datetime("2021-10-01 00:00:00", tz = "UTC")
end_time <- as_datetime("2022-09-30 23:00:00", tz = "UTC")
complete_time_sequence <- seq(start_time, end_time, by = "60 mins")
dataset <- data.table(
Time = as.POSIXct(character(),tz = "UTC",format = "%Y-%m-%d %H:%M:%S"),
Location = character(),
Demand_aggregated = numeric()
)
for (i in 1:length(complete_time_sequence)){
time <- format(complete_time_sequence[i], "%Y-%m-%d %H:%M:%S")
bin <- ChargingRecords %>%
filter(StartDatehour == ymd_hms(time) | EndDatehour == ymd_hms(time))
if (nrow(bin) != 0){
for (j in 1:nrow(bin)){
row <- bin[j]
start_day <- row$StartDay
end_day <- row$EndDay
start_time <- row$Startmin
end_time <- row$Endmin
demand <- as.numeric(row$Demand)
location <- row$Location
if (start_day == end_day) {
total_minutes <- end_time - start_time
interval_minutes <- (hour(time)+1)*60 - start_time
interval_demand <- demand * interval_minutes / total_minutes
} else {
if (as.Date(time) == start_day){
end_of_day_minutes <- 1440 - start_time
total_minutes <- end_of_day_minutes + end_time
interval_minutes <- (hour(time)+1)*60 - start_time
interval_demand <- (demand / total_minutes) * interval_minutes
} else{
end_of_day_minutes <- 1440 - start_time
total_minutes <- end_of_day_minutes + end_time
interval_minutes <- end_time - hour(time)*60
interval_demand <- (demand / total_minutes) * interval_minutes
}
}
new_row <- data.table(
Time = as.POSIXct(time,tz = "UTC",format = "%Y-%m-%d %H:%M:%S"),
Location = location,
Demand_aggregated = interval_demand
)
dataset <- rbind(dataset, new_row)
}
}
print(i)
}
View(dataset)
fwrite(dataset,"data_1h_loc.csv")
dataset_2 <- dataset %>%
mutate(Location_type = case_when(
Location %in% c("accommodation", "apartment", "camping", "hotel", "resort") ~ 1,
Location %in% c("company", "public area", "public institution", "public parking lot", "restaurant") ~ 2,
TRUE ~ 0
))
View(dataset_2)
i=1
time <- format(complete_time_sequence[i], "%Y-%m-%d %H:%M:%S")
bin <- ChargingRecords %>%
filter((StartDay == date(time) & StartDatehour <= ymd_hms(time) & EndDay == date(time)+1) |
(StartDay == date(time) & StartDatehour <= ymd_hms(time) & EndDay == date(time) & EndDatehour >= ymd_hms(time)) |
(StartDay == date(time)-1 & EndDay == date(time) & EndDatehour >= ymd_hms(time)))
View(bin)
library(maxLik)
library(miscTools)
library(fmlogit)
setwd("/Users/zheng73/Desktop/实习/投入产出/政策影响/FMNL")
dataset <- read.csv("data.csv")
View(dataset)
y <- dataset[,4:37]
y
x <- dataset[,c(2:3,38:52)]
fmlogit(y,x)
model <- fmlogit(y,x)
dataset$Country <- as.factor(dataset$Country)
dataset$Year <- as.factor(dataset$Year)
y <- dataset[,4:37]
x <- dataset[,c(2:3,38:52)]
model <- fmlogit(y,x)
model
library(boomer)
remotes::install_github("moodymudskipper/boomer")
library(devtools)
library(usethis)
require(devtools)
library(devtools)
library(usethis)
require(devtools)
install_github("moodymudskipper/boomer")
library(boomer)
rig(fmlogit)(y,x)
dataset <- read.csv("data.csv")
dataset$Country <- as.factor(dataset$Country)
dataset$Year <- as.factor(dataset$Year)
y <- dataset[,4:37]
x <- dataset[,c(2:3,38:52)]
rig(fmlogit)(y,x)
library(maxLik)
library(miscTools)
library(fmlogit)
